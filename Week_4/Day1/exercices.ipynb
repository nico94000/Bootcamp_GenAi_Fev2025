{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2400511504.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    importmport tensorflow as tf\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "importmport tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŒŸ Exercice 1 : Petit Quiz\n",
    "\n",
    "Quelle est la principale diffÃ©rence entre l'apprentissage automatique traditionnel et l'apprentissage profond ?\n",
    "L'apprentissage profond repose sur l'utilisation de reseaux de neurones artificiels.\n",
    "On peut traiter des donnÃ©es non structurÃ©es grace au deep learning \n",
    "\n",
    "\n",
    "Comment les rÃ©seaux de neurones artificiels (RNA) imitent-ils le cerveau humain ?\n",
    "ils fonctionnenet de la meme maniÃ¨re en envoyant une information en la traitant et la ressortant (input-traitement--output)\n",
    "\n",
    "Pourquoi l'apprentissage profond fonctionne-t-il mieux sur de grands ensembles de donnÃ©es par rapport Ã  l'apprentissage automatique traditionnel ?\n",
    "Car il permet d'analyser un plus grand nombre d'information Ã  la fois et surtout n'oblige pas a traiter et creer des modeles pour chaque fonctions .\n",
    "\n",
    "Quels sont les dÃ©fis de l'apprentissage profond et comment peuvent-ils Ãªtre relevÃ©s ?\n",
    "Ca demande beaucoup de ressources financieres mais aussi energetiques, il faut donc l'utiliser seulement lorsque c'est necessaire et que l'on voit que le maching learning n'est pas suffisant.\n",
    "\n",
    "Qu'est-ce que l'ingÃ©nierie des caractÃ©ristiques et pourquoi n'est-elle pas nÃ©cessaire dans l'apprentissage en profondeur ?\n",
    "Lâ€™ingÃ©nierie des caractÃ©ristiques est le processus de transformation des donnÃ©es brutes en caractÃ©ristiques exploitables pour un modÃ¨le. Dans lâ€™apprentissage profond, les couches cachÃ©es des rÃ©seaux neuronaux apprennent automatiquement ces reprÃ©sentations, rendant le processus manuel moins nÃ©cessaire.\n",
    "Les couches cachÃ©es permettent dâ€™extraire des caractÃ©ristiques de plus en plus complexes Ã  partir des donnÃ©es brutes. Chaque couche apprend des reprÃ©sentations abstraites qui aident Ã  la prise de dÃ©cision dans des tÃ¢ches complexes comme la reconnaissance dâ€™images ou le traitement du langage naturel.\n",
    "Quel rÃ´le jouent les couches cachÃ©es dans un modÃ¨le d'apprentissage profond ?\n",
    "PremiÃ¨res couches : dÃ©tectent des caractÃ©ristiques simples (bords, motifs basiques).\n",
    "Couches intermÃ©diaires : combinent ces motifs pour former des objets plus complexes.\n",
    "DerniÃ¨res couches : prennent des dÃ©cisions basÃ©es sur ces caractÃ©ristiques apprises.\n",
    "Dans un rÃ©seau neuronal artificiel (NN), quelle est la fonction d'une fonction d'activation ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.0\n"
     ]
    }
   ],
   "source": [
    "Temperature_weight = 0.6\n",
    "Rain_weight = 0.4\n",
    "Bias = 2 \n",
    "\n",
    "Temperature = 70 \n",
    "Rain = 0\n",
    "\n",
    "Sum = (Temperature*Temperature_weight)+(Rain*Rain_weight)+Bias\n",
    "print(Sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train_data, y_train_data)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/250\n",
    "x_test = x_test/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construction du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DÃ©finition du modÃ¨le\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Aplatit l'image 28x28 en un vecteur\n",
    "    keras.layers.Dense(128, activation='relu'),  # Couche dense avec 128 neurones et ReLU\n",
    "    keras.layers.Dense(10, activation='softmax')  # Couche de sortie pour 10 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10, 10, 10) and (32, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# EntraÃ®nement du modÃ¨le\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4x/y19tv9t12q123fdsq8qvdq_c0000gn/T/__autograph_generated_filewi2pi3jg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10, 10, 10) and (32, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Compilation du modÃ¨le\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de y_train avant l'encodage : (60000, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de y_train avant l'encodage :\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de y_train aprÃ¨s correction : (60000, 10, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# VÃ©rifie si les labels ne sont pas dÃ©jÃ  en one-hot\n",
    "if len(y_train.shape) == 1:\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Shape de y_train aprÃ¨s correction :\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = (w1*x1) + (w2*x2) +b\n",
    "z = (0,5*2000) + (0,7*3) +50000\n",
    "z = 1000 + 2,1 + 50000\n",
    "z = 51002,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ReLU (Rectified Linear Unit) est dÃ©finie par :\n",
    "\n",
    "ReLU(z)=max(0,z)\n",
    "Puisque z = 51002.1 est positif, on garde la valeur :\n",
    "ReLU(z)=51002.1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modÃ¨le prÃ©dit un prix de maison de 51,002.10 â‚¬ en fonction de la superficie et du nombre de chambres.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercice 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction: 36.4\n",
      "Loss: 1180.98\n",
      "Updated Weights: [ 2.544 39.18 ]\n",
      "Updated Bias: 10.486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize input data (features)\n",
    "x = np.array([4, 80])  # 4 hours studied, previous test score: 80\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.array([0.6, 0.3])  # Initial weights\n",
    "b = 10  # Initial bias\n",
    "\n",
    "# Forward Propagation\n",
    "def forward_propagation(x, w, b):\n",
    "    z = np.dot(x, w) + b  # Weighted sum\n",
    "    return z  # Linear activation (No ReLU here, it's a regression task)\n",
    "\n",
    "# Compute prediction\n",
    "y_pred = forward_propagation(x, w, b)\n",
    "y_true = 85  # Actual exam score\n",
    "\n",
    "# Compute Loss (Mean Squared Error)\n",
    "loss = 0.5 * (y_true - y_pred) ** 2\n",
    "\n",
    "# Compute Gradients\n",
    "grad_w = -(y_true - y_pred) * x  # Partial derivatives with respect to weights\n",
    "grad_b = -(y_true - y_pred)  # Partial derivative with respect to bias\n",
    "\n",
    "# Update Weights and Bias\n",
    "learning_rate = 0.01\n",
    "w_new = w - learning_rate * grad_w\n",
    "b_new = b - learning_rate * grad_b\n",
    "\n",
    "# Print Results\n",
    "print(\"Initial Prediction:\", y_pred)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Updated Weights:\", w_new)\n",
    "print(\"Updated Bias:\", b_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: packaging in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.5.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/Nicolas/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/Nicolas/.pyenv/versions/3.8.10/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2411 - accuracy: 0.9286 - val_loss: 0.1195 - val_accuracy: 0.9634\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 906us/step - loss: 0.1014 - accuracy: 0.9692 - val_loss: 0.1140 - val_accuracy: 0.9653\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.0716 - accuracy: 0.9779 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 912us/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.0848 - val_accuracy: 0.9724\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0954 - val_accuracy: 0.9731\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 844us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.0932 - val_accuracy: 0.9729\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.0758 - val_accuracy: 0.9791\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 854us/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0807 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 898us/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0878 - val_accuracy: 0.9786\n",
      "313/313 [==============================] - 0s 447us/step - loss: 0.0878 - accuracy: 0.9786\n",
      "Test Accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalisation\n",
    "\n",
    "# Construction du modÃ¨le\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Ã‰valuation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
